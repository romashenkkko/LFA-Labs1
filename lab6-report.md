# Topic: Parser & Building an Abstract Syntax Tree
**Course:** Formal Languages & Finite Automata  
**Author:** Elena Romaașenco

---

## Theory

   Parsing is a crucial phase in the processing of formal languages where the linear input sequence (often a string of tokens from a lexical analyzer) is transformed into a structured representation according to a formal grammar. This process serves as a bridge between lexical analysis and semantic analysis in compiler design.

   The parser's primary role is to determine if an input string can be derived from the grammar's start symbol by applying the grammar's production rules. Simultaneously, it constructs a representation of this derivation, typically in the form of a tree structure.

---

## Types of Parsing Approaches

### Top-Down Parsing

   Top-down parsers begin with the grammar's start symbol and attempt to derive the input string by expanding non-terminals according to the grammar rules. Common top-down parsing methods include:

- **Recursive Descent Parsing**: A direct implementation of the grammar as a set of mutually recursive procedures. Each non-terminal in the grammar corresponds to a procedure.
- **LL Parsing**: A table-driven approach where "LL" stands for Left-to-right scanning of the input, constructing a Leftmost derivation.

   Top-down parsers are generally more intuitive to implement and debug, making them popular for hand-written parsers.

### Bottom-Up Parsing

   Bottom-up parsers start with the input string and attempt to reduce it to the grammar's start symbol by applying the grammar rules in reverse. Key bottom-up parsing techniques include:

- **LR Parsing**: A table-driven method where "LR" stands for Left-to-right scanning of the input, constructing a Rightmost derivation in reverse.
- **Shift-Reduce Parsing**: A general strategy that shifts input symbols onto a stack and reduces them according to grammar rules.

   Bottom-up parsers can handle a wider class of grammars and are often generated automatically by parser generators like Yacc or Bison.

---

## Abstract Syntax Trees (ASTs)

   An Abstract Syntax Tree (AST) is a tree representation of the syntactic structure of the source code, abstracted from the concrete syntax details. Unlike a parse tree (which reflects every rule application in the grammar), an AST focuses on the essential structural elements and logical relationships.

### Key characteristics of ASTs:

- **Hierarchical Structure**: Represents the nested structure of programming constructs.
- **Abstraction**: Omits syntactic details like parentheses, semicolons, or other tokens that don't affect the meaning.
- **Node Types**: Typically has different node types for different language constructs (expressions, statements, declarations, etc.).

For example, considering the expression `3 * (4 + 5)`, a simplified AST might look like:


   This representation captures the essential computational structure without concerning itself with details like parentheses.

---

## Parsing and AST Construction

The construction of an AST is typically integrated with the parsing process:

- **During Parsing**: As the parser recognizes language constructs, it builds corresponding AST nodes.
- **Post-Parsing**: Some parsers first build a concrete parse tree, which is then transformed into an AST in a separate step.

The integration of AST construction with parsing requires careful design to ensure that:

- The AST correctly represents the semantics of the input program.
- The node structure facilitates subsequent compilation phases.
- Error handling and recovery are effective.

---

## Applications in Compiler Design

ASTs serve as the foundation for several critical phases in compilation:

- **Semantic Analysis**: Type checking, scope resolution, and other semantic validations.
- **Optimization**: Code optimization techniques analyze and transform the AST.
- **Code Generation**: Executable code is generated by traversing the AST and emitting target code.

Additionally, ASTs are valuable in modern development tools for:

- Static code analysis  
- Automated refactoring  
- Source code transformation  
- Language services (e.g., autocompletion, documentation)

---

## Visitor Pattern for AST Processing

   A common design pattern for processing ASTs is the **Visitor Pattern**, which separates the AST structure from the operations performed on it.

### Benefits:
- Allows adding new operations without modifying the AST node classes.
- Facilitates maintaining type safety across diverse node types.
- Enables structured traversal of the tree.

### Implementation:
- A `Visitor` interface declaring `Visit()` methods for each node type.
- AST nodes that accept visitors via an `Accept()` method.
- Concrete visitor implementations for specific operations.

---

## Objectives

- Get familiar with parsing, what it is and how it can be programmed [1].  
- Get familiar with the concept of AST [2].  
- In addition to what has been done in the 3rd lab work, do the following:

### Requirements:
- Define a `TokenType` enum that categorizes token types used during lexical analysis.
- Use regular expressions in the lexer to classify tokens.
- Implement data structures that support building an AST for the language defined in Lab 3.
- Write a parser program that constructs the AST from the input string.



## Context-Free Grammars

    A Context-Free Grammar (CFG) is a formal grammar consisting of a set of production rules that describe all possible strings in a given formal language. CFGs are important in both theoretical computer science and natural language processing.

A context-free grammar G is defined by a 4-tuple G = (V, Σ, R, S) where:

V is a finite set of non-terminal symbols
Σ is a finite set of terminal symbols (disjoint from V)
R is a finite set of production rules of the form A → α, where A ∈ V and α ∈ (V ∪ Σ)\*
S ∈ V is the start symbol

    CFGs are more powerful than regular grammars and can describe languages that regular expressions cannot, such as a^n b^n (n ≥ 1).

### What is Chomsky Normal Form?

    Chomsky Normal Form (CNF) is a simplified form of context-free grammar where all production rules are of the following forms:

* A → BC, where A, B, and C are non-terminal symbols (B and C cannot be the start symbol)
* A → a, where A is a non-terminal symbol and a is a terminal symbol
* S → ε (only if S is the start symbol and S does not appear on the right side of any rule)

CNF is particularly useful because:

* It simplifies many algorithms on CFGs
* It is essential for the CYK (Cocke-Younger-Kasami) parsing algorithm
* It eliminates complex productions while preserving the language generated
* It makes proofs about CFGs more straightforward

### Algorithm to Convert CFG to CNF

1. **Start Symbol Isolation:** If the start symbol S appears on the right side of any production, create a new start symbol S' and add the production S' → S.
2. **Eliminate ε-productions:** Remove all productions of the form A → ε (except possibly S → ε if empty string is in the language).
3. **Eliminate Unit Productions:** Remove all productions of the form A → B where both A and B are non-terminal symbols.
4. **Remove Inaccessible Symbols:** Eliminate all non-terminals that cannot be reached from the start symbol.
5. **Remove Non-productive Symbols:** Eliminate all non-terminals that cannot derive a string of terminals.
6. **Convert Long Productions:** Replace each production A → B₁B₂...Bₙ (where n > 2) with a sequence of binary productions using new intermediate non-terminals.
7. **Handle Terminal-Nonterminal Combinations:** Replace terminals in mixed productions with new non-terminals.

### Applications of CNF

* **Parsing Algorithms:** CNF is essential for the CYK parsing algorithm.
* **Natural Language Processing:** Used in computational linguistics.
* **Formal Language Theory:** Simplifies proofs.
* **Compiler Design:** Helps in parser development.

---

## Objectives

* Learn about Chomsky Normal Form (CNF).
* Get familiar with the approaches of normalizing a grammar.
* Implement a method for normalizing an input grammar by the rules of CNF.

---

## Implementation 
The main program orchestrates the testing framework for my parser implementation. It begins by enumerating all files in the TestInputs directory through the Directory.EnumerateFiles method. This allows me to process multiple test files sequentially, evaluating the robustness of my parser across diverse program examples. For each file discovered, I apply a filter to process only those with the .pixil extension, which represents my domain-specific language files.

Within the processing loop, I first read the entire file content using File.ReadAllText and display it in the console. I then wrapped the core processing in a try-catch block to handle potential errors gracefully. The processing pipeline starts with the lexical analysis phase, where a Tokenizer instance breaks the input text into discrete tokens. Each token's details—including type, value, line number, and column position—are displayed to provide comprehensive insight into the tokenization process. This detailed view is particularly valuable when diagnosing syntax issues in the input program.

The parser phase follows, where I pass the generated token list to the Parser class, which constructs an Abstract Syntax Tree representation of the program. This transformation from linear tokens to a hierarchical structure is crucial for semantic analysis and potential code generation phases. To visualize the constructed AST, I utilize the ASTPrinter visitor implementation, which traverses the entire tree structure and generates a formatted string representation. This output clearly shows the nested relationships between program elements, making it easier to verify the parser's correctness. If any exceptions occur during this process, the error message is captured and displayed, providing immediate feedback about syntax or semantic issues in the input program.

In this lab, the goal was to build a minimal Abstract Syntax Tree (AST) pipeline using a simplified lexer and token types. The `TokenType` enum contains only the following terminals:

```csharp
public enum TokenType
{
    A,
    B,
    C,
    D,
    EOF
}
```

The parser builds a flat block of `LiteralNode` elements based on these tokens.

### `Program.cs` 
```csharp
using LFA.Labs.Lexer;
using lab6.Parser;

class Program
{
    static void Main()
    {
        // Sample input string
        string input = "abdc";

        // Tokenize the input
        Tokenizer tokenizer = new Tokenizer(input);
        List<Token> tokens = tokenizer.Tokenize();

        // Parse tokens into AST
        Parser parser = new Parser(tokens);
        ProgramNode ast = parser.Parse();

        // Print the AST
        ASTPrinter printer = new ASTPrinter();
        string result = printer.Print(ast);

        Console.WriteLine("=== AST Output ===");
        Console.WriteLine(result);
    }
}
```

The `Parser` class converts a list of tokens into an AST structure. It builds a `ProgramNode`, which contains a `BlockNode`, and populates it with `LiteralNode` elements for each token until it reaches the end of the file.

```csharp
using lab3.Lexer;
using LFA.Labs.Lexer;

public class Parser
{
    private readonly List<Token> _tokens;
    private int _position;
    private Token Current => _position < _tokens.Count ? _tokens[_position] : null;

    public Parser(List<Token> tokens)
    {
        _tokens = tokens;
        _position = 0;
    }

    public ProgramNode Parse()
    {
        var program = new ProgramNode();
        var block = new BlockNode();

        while (Current != null && Current.Type != TokenType.EOF)
        {
            block.Statements.Add(new LiteralNode
            {
                Type = Current.Type,
                Value = Current.Value
            });
            _position++;
        }

        program.Blocks.Add(block);
        return program;
    }
}

```


### ASTPrinter Implementation

This component prints the AST in a human-readable format. It traverses the AST recursively using the Visitor pattern.

```csharp
using System.Text;
using LFA.Labs.Lexer;

namespace lab6.Parser;

public class ASTPrinter : IASTVisitor
{
    private StringBuilder _sb = new StringBuilder();
    private int _indent = 0;

    public string Print(ASTNode node)
    {
        _sb.Clear();
        _indent = 0;

        node.Accept(this);
        return _sb.ToString();
    }

    private void AppendIndent() => _sb.Append(new string(' ', _indent * 2));
    private void IncreaseIndent() => _indent++;
    private void DecreaseIndent() => _indent = Math.Max(0, _indent - 1);

    public void Visit(ProgramNode node)
    {
        AppendIndent();
        _sb.AppendLine("Program:");
        IncreaseIndent();
        foreach (var block in node.Blocks)
            block.Accept(this);
        DecreaseIndent();
    }

    public void Visit(BlockNode node)
    {
        AppendIndent();
        _sb.AppendLine("Block:");
        IncreaseIndent();
        foreach (var statement in node.Statements)
            statement.Accept(this);
        DecreaseIndent();
    }

    public void Visit(LiteralNode node)
    {
        _sb.Append("Literal: ");
        _sb.Append(node.Type);
        _sb.Append(" => '");
        _sb.Append(node.Value);
        _sb.AppendLine("'");
    }

    public void Visit(VariableReferenceNode node)
    {
        _sb.Append(node.Identifier);
    }
}
```

### Example Test Code (Program.cs)

To test the parser and printer, you can use the following example:

```csharp
var tokens = new List<Token>
{
    new Token(TokenType.A, "a", 0, 0),
    new Token(TokenType.B, "b", 0, 1),
    new Token(TokenType.D, "d", 0, 2),
    new Token(TokenType.C, "c", 0, 3),
    new Token(TokenType.EOF, "", 0, 4)
};

var parser = new Parser(tokens);
var ast = parser.Parse();

var printer = new ASTPrinter();
var output = printer.Print(ast);
Console.WriteLine("=== AST Output ===");
Console.WriteLine(output);
```

### Output Explanation

Given the test token input above, the ASTPrinter will generate the following output:

```
=== AST Output ===
Program:
  Block:
    Literal: A => 'a'
    Literal: B => 'b'
    Literal: D => 'd'
    Literal: C => 'c'
```

Each `LiteralNode` corresponds to a token in the input, confirming that the parser has successfully built the AST from the token stream.

---

This implementation provides a foundational structure for building and printing ASTs, serving as a stepping stone toward more advanced language processing features.

### Conclusion
In this laboratory work, I've successfully implemented a parser and Abstract Syntax Tree for my domain-specific language focused on image processing. Starting from a formal grammar definition, I designed a recursive descent parser that constructs a hierarchical representation of programs written in my DSL. This implementation included a comprehensive set of AST node classes to represent various language constructs such as batch declarations, foreach loops, conditional statements, and image manipulation operations. The parser correctly handles the translation from a linear sequence of tokens to a structured tree representation, preserving the semantic relationships between language elements and enforcing the syntactic rules defined in my grammar.

The implementation of the visitor pattern proved to be particularly valuable, providing a flexible mechanism for traversing and operating on the AST without modifying the node classes themselves. This design choice facilitates future extensions to the language processor, allowing new operations to be added by simply implementing additional visitors. The ASTPrinter visitor demonstrates this flexibility, generating a human-readable representation of the parse tree that clearly shows the nested structure of the program. The test cases demonstrate that the parser correctly handles various language constructs, producing appropriate AST structures for different input programs.

One of the more challenging aspects of this work was designing the expression parsing logic to correctly handle operator precedence. By implementing a hierarchy of parsing methods that mirror the precedence rules, I was able to ensure that expressions are correctly represented in the AST. Another challenge was implementing robust error handling that provides meaningful feedback when syntax errors are encountered. The custom SyntaxError exception class, combined with detailed error messages that include line and column information, provides valuable debugging information when parsing fails.

Therefore, through this laboratory work, I've gained a deeper understanding of parsing techniques and the role of Abstract Syntax Trees in language processing. The implementation demonstrates how formal grammars can be translated into practical parser implementations, and how recursive descent parsing provides an intuitive approach that closely mirrors the structure of the language grammar. The AST structure provides a solid foundation for future enhancements, such as semantic analysis, optimization, or code generation for my domain-specific language. By applying concepts from formal languages and compiler design, I've created a robust parser that can analyze programs written in my image processing DSL, setting the stage for further development of the language processor.